#!/usr/bin/env python3
import os
import sys
import json
import torch
import numpy as np
import base64
import tempfile
from io import BytesIO
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ Kokoroè·¯å¾„åˆ°Pythonè·¯å¾„
kokoro_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'kokoro-main-ref', 'kokoro.js')
if not os.path.exists(kokoro_path):
    kokoro_path = '/home/ubuntu/kokoro-main-ref/kokoro.js'
sys.path.append(kokoro_path)

# å¯¼å…¥çœŸå®çš„Kokoroæ¨¡å—
try:
    from kokoro.model import KModel
    from kokoro.pipeline import KPipeline
    from kokoro import ALIASES, LANG_CODES
    KOKORO_AVAILABLE = True
except ImportError as e:
    print(f"âŒ Failed to import Kokoro modules: {e}", file=sys.stderr)
    KOKORO_AVAILABLE = False

class KokoroTTSReal:
    def __init__(self):
        self.models = {}
        self.pipelines = {}
        self.device = None
        self.model = None
        
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        self.setup_device()
        
        # åˆå§‹åŒ–æ¨¡å‹
        if KOKORO_AVAILABLE:
            self.initialize_model()
        
        # å‘é€å°±ç»ªä¿¡å·
        self.send_ready_signal()
        
    def setup_device(self):
        """è®¾ç½®è®¡ç®—è®¾å¤‡ï¼Œä¼˜å…ˆä½¿ç”¨GPU"""
        try:
            # è®¾ç½®ä»£ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if os.environ.get('https_proxy') or os.environ.get('http_proxy'):
                print(f"ğŸŒ Using proxy: {os.environ.get('https_proxy', os.environ.get('http_proxy'))}", file=sys.stderr)
            
            if torch.cuda.is_available():
                self.device = 'cuda'
                gpu_name = torch.cuda.get_device_name(0)
                print(f"ğŸš€ Using GPU: {gpu_name}", file=sys.stderr)
                print(f"ğŸ“Š GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB", file=sys.stderr)
                print(f"ğŸ”¥ CUDA Version: {torch.version.cuda}", file=sys.stderr)
            elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                self.device = 'mps'
                print("ğŸ Using Apple Silicon MPS", file=sys.stderr)
            else:
                self.device = 'cpu'
                print("ğŸ’» Using CPU (slow)", file=sys.stderr)
            
            sys.stderr.flush()
            
        except Exception as e:
            self.device = 'cpu'
            print(f"âš ï¸ Device detection failed, falling back to CPU: {e}", file=sys.stderr)
            sys.stderr.flush()
    
    def send_ready_signal(self):
        """å‘é€å°±ç»ªä¿¡å·åˆ°stderrï¼Œè®©Node.jsçŸ¥é“æœåŠ¡å·²å‡†å¤‡å¥½"""
        if KOKORO_AVAILABLE and self.model:
            print("ğŸš€ Kokoro TTS service is ready with real GPU acceleration", file=sys.stderr)
        else:
            print("âš ï¸ Kokoro TTS service ready but using fallback mode", file=sys.stderr)
        sys.stderr.flush()
        
    def initialize_model(self):
        """åˆå§‹åŒ–Kokoroæ¨¡å‹"""
        try:
            print("ğŸ”„ Initializing Kokoro model...", file=sys.stderr)
            sys.stderr.flush()
            
            # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼Œä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
            local_model_path = '/home/ubuntu/Kokoro-82M'
            if os.path.exists(os.path.join(local_model_path, 'kokoro-v1_0.pth')):
                print(f"ğŸ“‚ Using local model at: {local_model_path}", file=sys.stderr)
                # å¯¹äºæœ¬åœ°æ¨¡å‹ï¼Œéœ€è¦è®¾ç½®ç¯å¢ƒå˜é‡è®©HuggingFaceä½¿ç”¨æœ¬åœ°ç¼“å­˜
                os.environ['HF_HOME'] = local_model_path
                os.environ['HF_HUB_CACHE'] = local_model_path
                # åˆ›å»ºç¬¦å·é“¾æ¥è®©HuggingFaceæ‰¾åˆ°æœ¬åœ°æ¨¡å‹
                hf_cache_dir = os.path.expanduser('~/.cache/huggingface/hub')
                os.makedirs(hf_cache_dir, exist_ok=True)
                local_link = os.path.join(hf_cache_dir, 'models--hexgrad--Kokoro-82M')
                if not os.path.exists(local_link):
                    try:
                        os.symlink(local_model_path, local_link)
                        print(f"ğŸ”— Created symlink: {local_link} -> {local_model_path}", file=sys.stderr)
                    except OSError:
                        pass  # å¯èƒ½å·²å­˜åœ¨æˆ–æƒé™ä¸è¶³
                self.model = KModel(
                    repo_id='hexgrad/Kokoro-82M',
                    disable_complex=False
                )
            else:
                print("ğŸŒ Using HuggingFace model: hexgrad/Kokoro-82M", file=sys.stderr)
                self.model = KModel(
                    repo_id='hexgrad/Kokoro-82M',
                    disable_complex=False
                )
            
            # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            if self.device != 'cpu':
                self.model = self.model.to(self.device)
                
            print(f"âœ… Model initialized on {self.device}", file=sys.stderr)
            sys.stderr.flush()
            
        except Exception as e:
            print(f"âŒ Model initialization failed: {e}", file=sys.stderr)
            sys.stderr.flush()
            self.model = None
    
    def get_pipeline(self, lang_code='en-us', voice='af'):
        """è·å–æˆ–åˆ›å»ºè¯­è¨€ç®¡é“"""
        pipeline_key = f"{lang_code}_{voice}"
        
        if pipeline_key in self.pipelines:
            return self.pipelines[pipeline_key]
            
        try:
            print(f"ğŸ”„ Creating pipeline for {lang_code} with voice {voice}...", file=sys.stderr)
            sys.stderr.flush()
            
            # åˆ›å»ºç®¡é“
            pipeline = KPipeline(
                lang_code=lang_code,
                model=self.model if self.model else True,
                device=self.device if self.device != 'cpu' else None,
                repo_id='hexgrad/Kokoro-82M'  # ä½¿ç”¨æ ‡å‡†repo_idï¼Œæœ¬åœ°æ–‡ä»¶é€šè¿‡ç¼“å­˜è®¿é—®
            )
            
            self.pipelines[pipeline_key] = pipeline
            
            print(f"âœ… Pipeline created for {lang_code}_{voice}", file=sys.stderr)
            sys.stderr.flush()
            
            return pipeline
            
        except Exception as e:
            print(f"âŒ Pipeline creation failed for {lang_code}_{voice}: {e}", file=sys.stderr)
            sys.stderr.flush()
            return None
    
    def synthesize_audio(self, text, voice='af', speed=1.0, lang_code='en-us'):
        """ä½¿ç”¨çœŸå®Kokoroæ¨¡å‹åˆæˆéŸ³é¢‘"""
        try:
            if not KOKORO_AVAILABLE:
                raise Exception("Kokoro modules not available")
                
            if not self.model:
                raise Exception("Model not initialized")
            
            print(f"ğŸ¤ Synthesizing audio: {text[:50]}...", file=sys.stderr)
            print(f"ğŸ­ Voice: {voice}, Language: {lang_code}, Speed: {speed}", file=sys.stderr)
            sys.stderr.flush()
            
            # è·å–ç®¡é“
            pipeline = self.get_pipeline(lang_code, voice)
            if not pipeline:
                raise Exception(f"Failed to create pipeline for {lang_code}")
            
            # ä½¿ç”¨ç®¡é“ç”ŸæˆéŸ³é¢‘
            results = list(pipeline(text, voice=voice, speed=speed))
            
            if not results or len(results) == 0:
                raise Exception("No audio generated")
            
            # è·å–æœ€åä¸€æ®µéŸ³é¢‘ï¼ˆå®Œæ•´çš„éŸ³é¢‘ï¼‰
            graphemes, phonemes, audio = results[-1]
            
            if audio is None:
                raise Exception("No audio data generated")
            
            # ç¡®ä¿éŸ³é¢‘åœ¨CPUä¸Šå¤„ç†
            if isinstance(audio, torch.Tensor):
                audio = audio.cpu()
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_array = audio.numpy() if hasattr(audio, 'numpy') else np.array(audio)
            
            # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯float32æ ¼å¼
            if audio_array.dtype != np.float32:
                audio_array = audio_array.astype(np.float32)
            
            # å½’ä¸€åŒ–éŸ³é¢‘åˆ°[-1, 1]èŒƒå›´
            max_val = np.abs(audio_array).max()
            if max_val > 0:
                audio_array = audio_array / max_val * 0.95  # ç•™ä¸€äº›ä½™é‡é¿å…å‰Šæ³¢
            
            # Kokoroé»˜è®¤é‡‡æ ·ç‡æ˜¯24000Hz
            sample_rate = 24000
            
            # è½¬æ¢ä¸º16ä½æ•´æ•°
            audio_int16 = (audio_array * 32767).astype(np.int16)
            
            print(f"ğŸµ Audio generated: {len(audio_int16)} samples at {sample_rate}Hz", file=sys.stderr)
            sys.stderr.flush()
            
            # åˆ›å»ºWAVæ–‡ä»¶
            try:
                import scipy.io.wavfile
                
                # å†™å…¥ä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                    scipy.io.wavfile.write(tmp_file.name, sample_rate, audio_int16)
                    
                    # è¯»å–æ–‡ä»¶å†…å®¹
                    with open(tmp_file.name, 'rb') as f:
                        audio_bytes = f.read()
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.unlink(tmp_file.name)
                
                # è½¬æ¢ä¸ºhexå­—ç¬¦ä¸²
                audio_hex = audio_bytes.hex()
                
                print(f"âœ… Audio synthesized successfully: {len(audio_hex)} hex chars", file=sys.stderr)
                print(f"ğŸ“Š Audio size: {len(audio_bytes)} bytes", file=sys.stderr)
                sys.stderr.flush()
                
                return audio_hex
                
            except ImportError:
                raise Exception("scipy not available for WAV creation")
                
        except Exception as e:
            print(f"âŒ Audio synthesis failed: {e}", file=sys.stderr)
            sys.stderr.flush()
            raise Exception(f"Audio synthesis failed: {e}")
    
    def process_request(self, request_data):
        """å¤„ç†JSONè¯·æ±‚"""
        try:
            request = json.loads(request_data)
            
            text = request.get('text', '')
            speed = request.get('speed', 1.0)
            voice = request.get('voice', 'af')
            lang_code = request.get('lang_code', 'en-us')
            
            if not text:
                return {
                    'success': False,
                    'error': 'Text cannot be empty'
                }
            
            # åˆæˆéŸ³é¢‘
            audio_data = self.synthesize_audio(text, voice, speed, lang_code)
            
            return {
                'success': True,
                'audio_data': audio_data,
                'device': self.device,
                'message': f'Audio synthesized using {self.device} with voice: {voice}'
            }
            
        except json.JSONDecodeError:
            return {
                'success': False,
                'error': 'Invalid JSON request'
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def run(self):
        """è¿è¡Œäº¤äº’å¼æœåŠ¡"""
        while True:
            try:
                # è¯»å–è¾“å…¥
                line = sys.stdin.readline()
                if not line:
                    break
                    
                line = line.strip()
                if not line:
                    continue
                
                # å¤„ç†è¯·æ±‚
                response = self.process_request(line)
                
                # å‘é€å“åº”
                print(json.dumps(response), flush=True)
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                error_response = {
                    'success': False,
                    'error': f'Service error: {e}'
                }
                print(json.dumps(error_response), flush=True)

def main():
    """ä¸»å‡½æ•°"""
    try:
        service = KokoroTTSReal()
        service.run()
    except Exception as e:
        print(f"Failed to start Kokoro TTS service: {e}", file=sys.stderr)
        sys.exit(1)

if __name__ == '__main__':
    main()