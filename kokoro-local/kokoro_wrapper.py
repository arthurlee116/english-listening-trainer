#!/usr/bin/env python3
"""
Kokoro TTS Wrapper for Apple Silicon M4/Metal Acceleration
æœ¬åœ°TTSæœåŠ¡åŒ…è£…å™¨ï¼Œæ”¯æŒMetalåŠ é€Ÿå’Œæ¨¡å‹é¢„åŠ è½½
"""

import asyncio
import json
import sys
import os
import logging
from typing import Optional
import torch
import soundfile as sf
import io

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)

# è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ä»¥é¿å…macOSä¸Šçš„é—®é¢˜
if sys.platform == "darwin":
    import asyncio
    if sys.version_info >= (3, 8):
        asyncio.set_event_loop_policy(asyncio.DefaultEventLoopPolicy())

class KokoroTTSWrapper:
    """Kokoro TTSæœåŠ¡åŒ…è£…å™¨ï¼Œæ”¯æŒåŠ¨æ€è¯­è¨€é…ç½®"""
    
    def __init__(self, lang_code: str = 'a', voice: str = 'af_heart'):
        self.pipeline = None
        self.device = None
        self.voice_pack = None
        self.initialized = False
        self.lang_code = lang_code
        self.voice = voice
        self.current_lang_code = None
        self.current_voice = None
        
    def setup_device(self):
        """è®¾ç½®è®¡ç®—è®¾å¤‡ (ä¼˜å…ˆä½¿ç”¨MPS for M4)"""
        try:
            if torch.backends.mps.is_available():
                self.device = 'mps'
                # å¯ç”¨MPSå›é€€
                os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                print("ğŸš€ Using Metal Performance Shaders (MPS) for Apple Silicon", file=sys.stderr)
            else:
                self.device = 'cpu'
                print("ğŸ“± Using CPU for TTS processing", file=sys.stderr)
        except Exception as e:
            print(f"ERROR in setup_device: {e}", file=sys.stderr)
            self.device = 'cpu'  # å›é€€åˆ°CPU
            
    async def initialize(self, lang_code: Optional[str] = None, voice: Optional[str] = None):
        """åˆå§‹åŒ–æˆ–é‡æ–°åˆå§‹åŒ–Kokoroæ¨¡å‹å’Œè¯­éŸ³"""
        # æ›´æ–°è¯­è¨€å’Œè¯­éŸ³é…ç½®
        if lang_code is not None:
            self.lang_code = lang_code
        if voice is not None:
            self.voice = voice
            
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–
        need_reinit = (
            not self.initialized or 
            self.current_lang_code != self.lang_code or
            self.current_voice != self.voice
        )
        
        if not need_reinit:
            return
            
        try:
            self.setup_device()
            
            if not self.device:
                raise Exception("Failed to setup device")
            
            # å¯¼å…¥Kokoro (å»¶è¿Ÿå¯¼å…¥ä»¥å¤„ç†å¯èƒ½çš„ä¾èµ–é—®é¢˜)
            sys.path.append('/Users/arthur/Code/0712/kokoro-main-ref')
            from kokoro.pipeline import KPipeline
            
            # ç¦ç”¨kokoroå†…éƒ¨æ—¥å¿—
            import kokoro
            kokoro.logger.disable("kokoro")
            
            # åˆå§‹åŒ–pipeline (å¦‚æœè¯­è¨€æ”¹å˜éœ€è¦é‡æ–°åˆ›å»º)
            if self.current_lang_code != self.lang_code:
                print(f"ğŸŒ Initializing pipeline for language: {self.lang_code}", file=sys.stderr)
                self.pipeline = KPipeline(lang_code=self.lang_code)
                self.current_lang_code = self.lang_code
            
            # åŠ è½½è¯­éŸ³ (å¦‚æœè¯­éŸ³æ”¹å˜éœ€è¦é‡æ–°åŠ è½½)
            if self.current_voice != self.voice:
                try:
                    print(f"ğŸµ Loading voice: {self.voice}", file=sys.stderr)
                    self.voice_pack = self.pipeline.load_voice(self.voice)
                    self.current_voice = self.voice
                except Exception as e:
                    print(f"âš ï¸  Warning: Failed to load voice {self.voice}: {e}", file=sys.stderr)
                    # å°è¯•åŠ è½½é»˜è®¤è¯­éŸ³
                    try:
                        fallback_voice = 'af_heart' if self.lang_code == 'a' else f"{self.lang_code}f_alpha"
                        print(f"ğŸ”„ Trying fallback voice: {fallback_voice}", file=sys.stderr)
                        self.voice_pack = self.pipeline.load_voice(fallback_voice)
                        self.voice = fallback_voice
                        self.current_voice = fallback_voice
                    except Exception as e2:
                        print(f"âŒ Fallback voice also failed: {e2}", file=sys.stderr)
                        self.voice_pack = None
            
            self.initialized = True
            
            # å‘é€å°±ç»ªä¿¡å·åˆ°stderr
            print(f'ğŸš€ Kokoro TTS service ready - Language: {self.lang_code}, Voice: {self.voice}', file=sys.stderr)
            sys.stderr.flush()
            
        except Exception as e:
            print(f"âŒ Initialization failed: {e}", file=sys.stderr)
            raise
            
    async def generate_speech(self, text: str, speed: float = 1.0, parallel: bool = True) -> str:
        """ç”ŸæˆéŸ³é¢‘ï¼Œè¿”å›åå…­è¿›åˆ¶å­—ç¬¦ä¸²"""
        if not self.initialized:
            await self.initialize()
            
        if not text or not text.strip():
            raise ValueError("Text cannot be empty")
        
        # å¤„ç†é•¿æ–‡æœ¬ï¼šåˆ†å—è€Œä¸æ˜¯æˆªå–
        print(f"ğŸ” Text length check: {len(text)} chars", file=sys.stderr)
        if len(text) > 500:
            print(f"ğŸ“ Text is long ({len(text)} chars), will chunk into smaller pieces", file=sys.stderr)
            return await self.generate_speech_chunked(text, speed)
            
        # å¯¹äºçŸ­æ–‡æœ¬ï¼Œç›´æ¥ä½¿ç”¨å•å—å¤„ç†
        return await self.generate_speech_single(text, speed)
    
    def split_text_intelligently(self, text: str, max_chunk_size: int = 400) -> list:
        """æ™ºèƒ½åˆ†å‰²æ–‡æœ¬ï¼Œä¼˜å…ˆåœ¨å¥å­è¾¹ç•Œåˆ†å‰²"""
        chunks = []
        
        # å…ˆæŒ‰æ®µè½åˆ†å‰²
        paragraphs = text.split('\n\n')
        current_chunk = ""
        
        for paragraph in paragraphs:
            # å¦‚æœå½“å‰å—åŠ ä¸Šæ–°æ®µè½ä¸ä¼šå¤ªé•¿ï¼Œå°±æ·»åŠ 
            if len(current_chunk + paragraph) <= max_chunk_size:
                current_chunk += paragraph + "\n\n"
            else:
                # å¦‚æœå½“å‰å—ä¸ä¸ºç©ºï¼Œå…ˆä¿å­˜
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                    current_chunk = ""
                
                # å¦‚æœå•ä¸ªæ®µè½å¤ªé•¿ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²
                if len(paragraph) > max_chunk_size:
                    sentences = self.split_by_sentences(paragraph, max_chunk_size)
                    chunks.extend(sentences)
                else:
                    current_chunk = paragraph + "\n\n"
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def split_by_sentences(self, text: str, max_chunk_size: int) -> list:
        """æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬"""
        import re
        
        # æŒ‰å¥å­åˆ†å‰²ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼‰
        sentences = re.split(r'(?<=[.!?])\s+', text)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk + sentence) <= max_chunk_size:
                current_chunk += sentence + " "
            else:
                if current_chunk.strip():
                    chunks.append(current_chunk.strip())
                    current_chunk = ""
                
                # å¦‚æœå•ä¸ªå¥å­å¤ªé•¿ï¼ŒæŒ‰é€—å·åˆ†å‰²
                if len(sentence) > max_chunk_size:
                    sub_chunks = self.split_by_commas(sentence, max_chunk_size)
                    chunks.extend(sub_chunks)
                else:
                    current_chunk = sentence + " "
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def split_by_commas(self, text: str, max_chunk_size: int) -> list:
        """æŒ‰é€—å·åˆ†å‰²æ–‡æœ¬"""
        parts = text.split(', ')
        chunks = []
        current_chunk = ""
        
        for part in parts:
            if len(current_chunk + part) <= max_chunk_size:
                current_chunk += part + ", "
            else:
                if current_chunk.strip():
                    chunks.append(current_chunk.rstrip(', '))
                    current_chunk = ""
                
                # å¦‚æœå•ä¸ªéƒ¨åˆ†è¿˜æ˜¯å¤ªé•¿ï¼Œå¼ºåˆ¶åˆ†å‰²
                if len(part) > max_chunk_size:
                    while len(part) > max_chunk_size:
                        chunks.append(part[:max_chunk_size])
                        part = part[max_chunk_size:]
                    if part:
                        current_chunk = part + ", "
                else:
                    current_chunk = part + ", "
        
        if current_chunk.strip():
            chunks.append(current_chunk.rstrip(', '))
        
        return chunks
    
    async def generate_speech_chunked(self, text: str, speed: float = 1.0) -> str:
        """åˆ†å—ç”ŸæˆéŸ³é¢‘å¹¶æ‹¼æ¥"""
        chunks = self.split_text_intelligently(text)
        print(f"ğŸ§© Split text into {len(chunks)} chunks", file=sys.stderr)
        
        audio_chunks = []
        
        for i, chunk in enumerate(chunks):
            print(f"ğŸµ Processing chunk {i+1}/{len(chunks)}: {len(chunk)} chars", file=sys.stderr)
            
            try:
                # ä¸ºæ¯ä¸ªå—ç”ŸæˆéŸ³é¢‘
                chunk_audio_hex = await self.generate_speech_single(chunk, speed)
                
                # å°†åå…­è¿›åˆ¶è½¬æ¢ä¸ºå­—èŠ‚
                chunk_audio_bytes = bytes.fromhex(chunk_audio_hex)
                
                # è§£æWAVæ–‡ä»¶ï¼Œæå–éŸ³é¢‘æ•°æ®éƒ¨åˆ†ï¼ˆè·³è¿‡WAVå¤´ï¼‰
                if chunk_audio_bytes.startswith(b'RIFF'):
                    # æ‰¾åˆ°dataå—çš„ä½ç½®
                    data_pos = chunk_audio_bytes.find(b'data')
                    if data_pos == -1:
                        print(f"âŒ No data chunk found in audio file", file=sys.stderr)
                        continue
                    
                    # dataå—å¤´éƒ¨åŒ…å« 'data' + 4å­—èŠ‚å¤§å°ä¿¡æ¯
                    data_start = data_pos + 8
                    
                    # éªŒè¯dataå—å¤§å°
                    if data_start >= len(chunk_audio_bytes):
                        print(f"âŒ Invalid data chunk position", file=sys.stderr)
                        continue
                        
                    audio_data = chunk_audio_bytes[data_start:]
                    audio_chunks.append(audio_data)
                    print(f"âœ… Extracted {len(audio_data)} bytes of audio data from chunk", file=sys.stderr)
                else:
                    # å¦‚æœä¸æ˜¯æ ‡å‡†WAVæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                    audio_chunks.append(chunk_audio_bytes)
                    print(f"âœ… Using raw audio data: {len(chunk_audio_bytes)} bytes", file=sys.stderr)
                
                print(f"âœ… Chunk {i+1} completed ({len(audio_data)} bytes)", file=sys.stderr)
                
            except Exception as e:
                print(f"âŒ Chunk {i+1} failed: {e}", file=sys.stderr)
                # ç»§ç»­å¤„ç†å…¶ä»–å—
                continue
        
        if not audio_chunks:
            raise Exception("No audio chunks were generated successfully")
        
        # æ‹¼æ¥æ‰€æœ‰éŸ³é¢‘æ•°æ®
        combined_audio_data = b''.join(audio_chunks)
        
        # ç¡®ä¿éŸ³é¢‘æ•°æ®å¯¹é½åˆ°æ ·æœ¬è¾¹ç•Œ (16ä½=2å­—èŠ‚å¯¹é½)
        if len(combined_audio_data) % 2 != 0:
            combined_audio_data += b'\x00'  # å¡«å……ä¸€ä¸ªå­—èŠ‚
        
        # åˆ›å»ºæ–°çš„WAVå¤´
        import struct
        sample_rate = 24000
        num_channels = 1
        bits_per_sample = 16
        byte_rate = sample_rate * num_channels * bits_per_sample // 8
        block_align = num_channels * bits_per_sample // 8
        data_size = len(combined_audio_data)
        file_size = 36 + data_size
        
        # ç¡®ä¿WAVå¤´å®Œå…¨æ­£ç¡® (RIFFæ–‡ä»¶å¤§å°åº”è¯¥æ˜¯æ•´ä¸ªæ–‡ä»¶å‡å»8å­—èŠ‚)
        riff_size = 36 + data_size  # fmt chunk (24 bytes) + data chunk header (8 bytes) + data
        wav_header = struct.pack('<4sI4s4sIHHIIHH4sI',
            b'RIFF',           # ChunkID
            riff_size,         # ChunkSize (æ•´ä¸ªæ–‡ä»¶å¤§å° - 8)
            b'WAVE',           # Format
            b'fmt ',           # Subchunk1ID
            16,                # Subchunk1Size (PCM = 16)
            1,                 # AudioFormat (PCM = 1)
            num_channels,      # NumChannels
            sample_rate,       # SampleRate
            byte_rate,         # ByteRate
            block_align,       # BlockAlign
            bits_per_sample,   # BitsPerSample
            b'data',           # Subchunk2ID
            data_size          # Subchunk2Size
        )
        
        print(f"ğŸ”§ WAV Header Info:", file=sys.stderr)
        print(f"  - Sample Rate: {sample_rate} Hz", file=sys.stderr)
        print(f"  - Channels: {num_channels}", file=sys.stderr)
        print(f"  - Bit Depth: {bits_per_sample} bits", file=sys.stderr)
        print(f"  - Data Size: {data_size} bytes", file=sys.stderr)
        print(f"  - File Size: {file_size + 8} bytes", file=sys.stderr)
        
        # ç»„åˆå®Œæ•´çš„WAVæ–‡ä»¶
        complete_wav = wav_header + combined_audio_data
        
        total_duration = len(combined_audio_data) / (sample_rate * num_channels * bits_per_sample // 8)
        print(f"ğŸµ Combined {len(chunks)} chunks, total length: {total_duration:.2f}s", file=sys.stderr)
        
        return complete_wav.hex()
    
    async def generate_speech_single(self, text: str, speed: float = 1.0) -> str:
        """ç”Ÿæˆå•ä¸ªæ–‡æœ¬å—çš„éŸ³é¢‘ï¼ˆåŸæ¥çš„generate_speeché€»è¾‘ï¼‰"""
        try:
            import torch
            import concurrent.futures
            
            # é¦–å…ˆæ”¶é›†æ‰€æœ‰æ–‡æœ¬å—
            text_chunks = []
            for i, (graphemes, phonemes, audio) in enumerate(
                self.pipeline(
                    text, 
                    voice=self.voice, 
                    speed=speed,
                    split_pattern=r'\n+'
                )
            ):
                if audio is not None:
                    text_chunks.append((i, graphemes, phonemes))
                    print(f"ğŸµ Found chunk {i+1}: {len(graphemes)} chars, {len(phonemes)} phonemes", file=sys.stderr)
            
            if not text_chunks:
                raise Exception("No audio chunks were generated")
            
            print(f"ğŸµ Total {len(text_chunks)} chunks to process", file=sys.stderr)
            
            # ä¸²è¡Œå¤„ç†ï¼ˆå•å—éŸ³é¢‘ä¸éœ€è¦å¹¶è¡Œï¼‰
            print(f"ğŸ“ Processing {len(text_chunks)} chunks sequentially...", file=sys.stderr)
            
            audio_chunks = []
            for i, (graphemes, phonemes, audio) in enumerate(
                self.pipeline(
                    text, 
                    voice=self.voice, 
                    speed=speed,
                    split_pattern=r'\n+'
                )
            ):
                if audio is not None:
                    if self.device == 'mps':
                        audio = audio.to('cpu')
                    audio_chunks.append(audio)
                    print(f"âœ… Chunk {i+1} completed", file=sys.stderr)
            
            if not audio_chunks:
                raise Exception("No audio chunks were generated successfully")
            
            # æ‹¼æ¥æ‰€æœ‰éŸ³é¢‘å—
            combined_audio = torch.cat(audio_chunks)
            
            # è½¬æ¢ä¸ºå­—èŠ‚æ•°æ®
            import io
            import soundfile as sf
            buffer = io.BytesIO()
            sf.write(buffer, combined_audio.numpy(), 24000, format='WAV')
            audio_data = buffer.getvalue()
            
            total_duration = len(combined_audio) / 24000
            print(f"ğŸµ Generated {len(audio_chunks)} chunks, total length: {total_duration:.2f}s", file=sys.stderr)
            
            return audio_data.hex()
            
        except Exception as e:
            print(f"âŒ Error in generate_speech_single: {e}", file=sys.stderr)
            import traceback
            traceback.print_exc()
            raise

async def main():
    """ä¸»å‡½æ•°ï¼šç›‘å¬stdinè¾“å…¥å¹¶å¤„ç†è¯·æ±‚"""
    service = KokoroTTSWrapper()
    
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        await service.initialize()
        
        # å‘é€å°±ç»ªä¿¡å·åˆ°stderr
        print('ğŸš€ Kokoro TTS service is ready', file=sys.stderr)
        sys.stderr.flush()
        
        # ç›‘å¬æ ‡å‡†è¾“å…¥
        while True:
            try:
                line = sys.stdin.readline()
                if not line:
                    break
                    
                line = line.strip()
                if not line:
                    continue
                    
                # è§£æJSONè¯·æ±‚
                request = json.loads(line)
                
                # è·å–è¯­è¨€å’Œè¯­éŸ³é…ç½®
                lang_code = request.get('lang_code', 'a')
                voice = request.get('voice', 'af_heart')
                
                # é‡æ–°åˆå§‹åŒ–æœåŠ¡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                await service.initialize(lang_code=lang_code, voice=voice)
                
                # å¤„ç†è¯·æ±‚
                result = await service.generate_speech(
                    text=request.get('text', ''),
                    speed=float(request.get('speed', 1.0))
                )
                
                # è¿”å›ç»“æœ
                response = {
                    "success": True,
                    "audio_data": result,
                    "device": service.device or "unknown",
                    "lang_code": service.lang_code,
                    "voice": service.voice,
                    "message": "Audio generated successfully"
                }
                
                # å‘é€JSONå“åº”
                json_response = json.dumps(response)
                print(json_response, flush=True)
                
            except json.JSONDecodeError:
                error_response = {
                    "success": False,
                    "error": "Invalid JSON format"
                }
                print(json.dumps(error_response))
                sys.stdout.flush()
                
            except Exception as e:
                error_response = {
                    "success": False,
                    "error": str(e)
                }
                print(json.dumps(error_response))
                sys.stdout.flush()
                
    except KeyboardInterrupt:
        pass
    except Exception as e:
        sys.exit(1)

# ç®€å•æµ‹è¯•å‡½æ•°
async def test():
    """æµ‹è¯•å‡½æ•°"""
    service = KokoroTTSWrapper()
    await service.initialize()
    result = await service.generate_speech("Hello test", 1.0)
    print(json.dumps({
        "success": True,
        "audio_data": result,
        "device": service.device or "unknown",
        "message": "Test completed"
    }))

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "--test":
        asyncio.run(test())
    else:
        asyncio.run(main())